

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/blog.png">
  <link rel="icon" href="/img/blog.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Yubiao Wang">
  <meta name="keywords" content="">
  
    <meta name="description" content="Titanic 生存率预测一、问题描述泰坦尼克号（Titanic）问题的背景就是那个大家都熟悉的『Jack and Rose』的故事，豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，无法人人都有，副船长发话了『lady and kid first！』，所以是否获救其实并非随机，而是基于一些背景而有rank先后的。训练和测试数据是一些乘客的个人信息以及存活状况，要尝试根据它生成合适的模型并预测其">
<meta property="og:type" content="article">
<meta property="og:title" content="kaggle Titanic问题(集成学习)">
<meta property="og:url" content="https://e-alan.github.io/2022/11/03/kaggle%20Titanic%E9%97%AE%E9%A2%98(%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0)/index.html">
<meta property="og:site_name" content="Blog of Alan">
<meta property="og:description" content="Titanic 生存率预测一、问题描述泰坦尼克号（Titanic）问题的背景就是那个大家都熟悉的『Jack and Rose』的故事，豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，无法人人都有，副船长发话了『lady and kid first！』，所以是否获救其实并非随机，而是基于一些背景而有rank先后的。训练和测试数据是一些乘客的个人信息以及存活状况，要尝试根据它生成合适的模型并预测其">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://e-alan.github.io/img/kaggle.jpg">
<meta property="article:published_time" content="2022-11-03T09:35:10.000Z">
<meta property="article:modified_time" content="2022-11-04T07:59:23.023Z">
<meta property="article:author" content="Yubiao Wang">
<meta property="article:tag" content="集成学习">
<meta property="article:tag" content="Titanic">
<meta property="article:tag" content="Kaggle">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://e-alan.github.io/img/kaggle.jpg">
  
  
  <title>kaggle Titanic问题(集成学习) - Blog of Alan</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"e-alan.github.io","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":"ture","baidu":"66fe493fc83f85768cab806da37aa086","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"3HI8ltHUAgcuyEezN3uHxMVi-gzGzoHsz","app_key":"NVy1rcbT5pmhJAfNq0dYvwc7","server_url":"https://3hi8lthu.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":"ture"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Alan&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/tree.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="kaggle Titanic问题(集成学习)"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-11-03 17:35" pubdate>
          2022年11月3日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          25k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          212 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">kaggle Titanic问题(集成学习)</h1>
            
            <div class="markdown-body">
              
              <h1 id="Titanic-生存率预测"><a href="#Titanic-生存率预测" class="headerlink" title="Titanic 生存率预测"></a>Titanic 生存率预测</h1><h3 id="一、问题描述"><a href="#一、问题描述" class="headerlink" title="一、问题描述"></a>一、问题描述</h3><p>泰坦尼克号（Titanic）问题的背景就是那个大家都熟悉的『Jack and Rose』的故事，豪华游艇倒了，大家都惊恐逃生，可是救生艇的数量有限，无法人人都有，副船长发话了『lady and kid first！』，所以是否获救其实并非随机，而是基于一些背景而有rank先后的。训练和测试数据是一些乘客的个人信息以及存活状况，要尝试根据它生成合适的模型并预测其他人（test.data中的新数据）的存活状况，模型最终结果保存在predictedData.csv中。</p>
<p>显然，这是一个二分类问题，我们学习使用集成学习方法进行建模求解。<br>数据集下载地址：kaggle官网 <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/titanic/data">https://www.kaggle.com/competitions/titanic/data</a></p>
<h3 id="开始加油！"><a href="#开始加油！" class="headerlink" title="开始加油！"></a>开始加油！</h3><p>(ง •̀_•́)ง (*•̀ㅂ•́)و</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#数据处理</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment">#import os</span><br><span class="hljs-comment">#绘图</span><br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>%matplotlib inline<br><span class="hljs-comment"># matplotlib支持中文</span><br>plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]  <span class="hljs-comment"># 用来正常显示中文标签</span><br>plt.rcParams[<span class="hljs-string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="hljs-literal">False</span>  <span class="hljs-comment"># 用来正常显示负号</span><br><br><span class="hljs-comment">#各种模型、数据处理方法</span><br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> LabelEncoder <span class="hljs-comment"># 对数据进行编码</span><br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split <br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression<br><span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC, LinearSVC <span class="hljs-comment">#支持向量机用于分类</span><br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><span class="hljs-keyword">from</span> sklearn.naive_bayes <span class="hljs-keyword">import</span> GaussianNB<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> Perceptron <span class="hljs-comment">#感知机</span><br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> SGDClassifier <span class="hljs-comment">#随机梯度下降分类</span><br><span class="hljs-keyword">from</span> sklearn.tree <span class="hljs-keyword">import</span> DecisionTreeClassifier<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> GradientBoostingClassifier<br><span class="hljs-keyword">from</span> xgboost <span class="hljs-keyword">import</span> XGBClassifier <br><span class="hljs-keyword">from</span> lightgbm <span class="hljs-keyword">import</span> LGBMClassifier<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV, cross_val_score, StratifiedKFold, learning_curve<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score <span class="hljs-comment"># 精度是比率tp /（tp + fp）</span><br><br><span class="hljs-keyword">import</span> warnings<br>warnings.filterwarnings(<span class="hljs-string">&#x27;ignore&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="二、数据读取和查看"><a href="#二、数据读取和查看" class="headerlink" title="二、数据读取和查看"></a>二、数据读取和查看</h3><p>首先读入数据，并且初步查看数据的记录数，字段数据类型，缺失等信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 读入数据</span><br>train_df = pd.read_csv(<span class="hljs-string">&#x27;data/train.csv&#x27;</span>)<br>test_df = pd.read_csv(<span class="hljs-string">&#x27;data/test.csv&#x27;</span>)<br>combine_df = pd.concat([train_df, test_df])<br><span class="hljs-comment"># concat默认拼接方式是上下堆叠</span><br></code></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看数据，展示前5行</span><br>train_df.head()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>

</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 查看数据类型等信息</span><br>train_df.info()<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
</code></pre>
<p>我们可以看到部分数据存在缺失，数据类型多样，后续需要进行相关的数据处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_df.describe()<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>714.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
      <td>891.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>446.000000</td>
      <td>0.383838</td>
      <td>2.308642</td>
      <td>29.699118</td>
      <td>0.523008</td>
      <td>0.381594</td>
      <td>32.204208</td>
    </tr>
    <tr>
      <th>std</th>
      <td>257.353842</td>
      <td>0.486592</td>
      <td>0.836071</td>
      <td>14.526497</td>
      <td>1.102743</td>
      <td>0.806057</td>
      <td>49.693429</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>223.500000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>20.125000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>7.910400</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>446.000000</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>28.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>14.454200</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>668.500000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>31.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>891.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>8.000000</td>
      <td>6.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>

</div>



<p>以上包含数值型数据（Numerical data）的统计特征</p>
<h3 id="三、数据探索与变量分析"><a href="#三、数据探索与变量分析" class="headerlink" title="三、数据探索与变量分析"></a>三、数据探索与变量分析</h3><p>首先通过pandas的corr()函数计算相关系数矩阵，初步探索各个字段与预测变量“Survived”的关系以及各个变量之间的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过相关系数矩阵初步观察特征与“Survived&quot;的关系</span><br><br>train_df_corr = train_df.drop(<span class="hljs-string">&#x27;PassengerId&#x27;</span>,axis=<span class="hljs-number">1</span>).corr()<br><br>f, ax = plt.subplots(figsize=(<span class="hljs-number">9</span>,<span class="hljs-number">6</span>))<br>plt.style.use(<span class="hljs-string">&#x27;ggplot&#x27;</span>)<br>sns.set_style(<span class="hljs-string">&#x27;darkgrid&#x27;</span>)<br>sns.<span class="hljs-built_in">set</span>(context=<span class="hljs-string">&quot;paper&quot;</span>, font=<span class="hljs-string">&quot;monospace&quot;</span>)<br><br>hm = sns.heatmap(train_df_corr, cmap=sns.diverging_palette(<span class="hljs-number">20</span>, <span class="hljs-number">220</span>, n=<span class="hljs-number">200</span>),cbar=<span class="hljs-literal">True</span>, annot=<span class="hljs-literal">True</span>, square=<span class="hljs-literal">True</span>, fmt=<span class="hljs-string">&#x27;.3f&#x27;</span>,<br>                 annot_kws=&#123;<span class="hljs-string">&#x27;size&#x27;</span>:<span class="hljs-number">12</span>&#125;)<span class="hljs-comment"># 使用了seaborn的diverging_palette调色</span><br>ax.set_xticklabels(train_df_corr.index, size=<span class="hljs-number">11</span>)<br>ax.set_yticklabels(train_df_corr.columns[:], size=<span class="hljs-number">11</span>)<br>ax.set_title(<span class="hljs-string">&#x27;train feature corr&#x27;</span>, fontsize=<span class="hljs-number">15</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;train feature corr&#39;)
</code></pre>
<p><img src="/img/output_11_1.png" srcset="/img/loading.gif" lazyload><br>​    </p>
<p>根据相关系数矩阵，我们初步分析可知：</p>
<ol>
<li>Fare（乘客费用）、Parch（同行的家长和孩子数目）与“Survived”正相关。<br>数据显示高费用顾客更可能获救；</li>
<li>SibSp（同行的兄弟姐妹和配偶数目）、Age（年龄）、Pclass（用户阶级）与<br>“Survived”负相关；其中Pclass的值越小用户所属的等级越高，表示等级高的乘客更可能获救，这是具有一定的合理性的。<br>……</li>
</ol>
<h3 id="四、特征探索"><a href="#四、特征探索" class="headerlink" title="四、特征探索"></a>四、特征探索</h3><h4 id="4-1-年龄（Name）"><a href="#4-1-年龄（Name）" class="headerlink" title="4.1 年龄（Name）"></a>4.1 年龄（Name）</h4><p>我们将可视化展示训练数据集中年龄的整体分布以及dead和alive乘客的数量分布统计。并进行对比分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br>fig, axes = plt.subplots(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">6</span>))<br>sns.distplot(train_df.Age.dropna(), rug=<span class="hljs-literal">True</span>, color=<span class="hljs-string">&#x27;b&#x27;</span>, ax=axes[<span class="hljs-number">0</span>])<br>ax0 = axes[<span class="hljs-number">0</span>]<br>ax0.tick_params(labelsize=<span class="hljs-number">10</span>)<br>ax0.set_title(<span class="hljs-string">&#x27;age distribution&#x27;</span>,fontsize=<span class="hljs-number">12</span>)<br>ax0.set_xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>ax0.set_ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br><br>ax1 = axes[<span class="hljs-number">1</span>]<br><span class="hljs-comment"># ax1.set_title(&#x27;age survived distribution&#x27;)</span><br>k1 = sns.distplot(train_df[train_df.Survived==<span class="hljs-number">0</span>].Age.dropna(), hist=<span class="hljs-literal">False</span>, color=<span class="hljs-string">&#x27;y&#x27;</span>, ax=ax1, label=<span class="hljs-string">&#x27;dead&#x27;</span>)<br>k2 = sns.distplot(train_df[train_df.Survived==<span class="hljs-number">1</span>].Age.dropna(), hist=<span class="hljs-literal">False</span>, color=<span class="hljs-string">&#x27;b&#x27;</span>, ax=ax1, label=<span class="hljs-string">&#x27;alive&#x27;</span>)<br>ax1.tick_params(labelsize=<span class="hljs-number">10</span>)<br>ax1.set_xlabel(<span class="hljs-string">&#x27;age survived distribution&#x27;</span>,fontsize=<span class="hljs-number">12</span>)<br>ax1.set_ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br><br>ax1.legend(fontsize=<span class="hljs-number">12</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&lt;matplotlib.legend.Legend at 0x24b9bfaffd0&gt;
</code></pre>
<p><img src="/img/output_14_1.png" srcset="/img/loading.gif" lazyload></p>
<p>乘客的年龄集中在20-40岁，所以主要为青年人和中年人。从age survived distribution表中我们可以发现，小孩获救似乎更容易一些，这个结果也有一定的社会基础，灾难时刻，大多数人可能选择站出来保护妇女和儿童。</p>
<h4 id="4-2-用户阶级（Pclass）"><a href="#4-2-用户阶级（Pclass）" class="headerlink" title="4.2 用户阶级（Pclass）"></a>4.2 用户阶级（Pclass）</h4><p>我们绘制柱形图展示不同Pclass（1， 2 ， 3）的乘客获救与未获救的数量，以对比发现Pclass与“Survived”的关系。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">y_dead = train_df[train_df.Survived==<span class="hljs-number">0</span>].groupby(<span class="hljs-string">&#x27;Pclass&#x27;</span>)[<span class="hljs-string">&#x27;Survived&#x27;</span>].count()<br>y_alive = train_df[train_df.Survived==<span class="hljs-number">1</span>].groupby(<span class="hljs-string">&#x27;Pclass&#x27;</span>)[<span class="hljs-string">&#x27;Survived&#x27;</span>].count()<br><br>pos = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]<br>ax = plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">4</span>)).add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>ax.bar(pos, y_dead, color=<span class="hljs-string">&#x27;r&#x27;</span>, alpha=<span class="hljs-number">0.5</span>, label=<span class="hljs-string">&#x27;dead&#x27;</span>)<br>ax.bar(pos, y_alive, color=<span class="hljs-string">&#x27;b&#x27;</span>, bottom=y_dead, alpha=<span class="hljs-number">0.5</span>, label=<span class="hljs-string">&#x27;alive&#x27;</span>)<br>ax.legend(fontsize=<span class="hljs-number">15</span>, loc=<span class="hljs-string">&#x27;best&#x27;</span>)<br>ax.set_xticks(pos)<br>ax.set_xticklabels([<span class="hljs-string">&#x27;Pclass %d&#x27;</span>%(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>)], size=<span class="hljs-number">12</span>)<br>ax.set_title(<span class="hljs-string">&#x27;Pclass Surveved count&#x27;</span>, size=<span class="hljs-number">15</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Pclass Surveved count&#39;)
</code></pre>
<p><img src="/img/output_17_1.png" srcset="/img/loading.gif" lazyload></p>
<p>Pclass从1至3等级递减，即1可以理解为头等乘客。我们发现在Pclass=1的记录中，乘客的获救比例明显最高，这是一个有趣的现象。或许更高等的乘客配备了更好的保护措施。</p>
<h4 id="4-3-性别（Sex）"><a href="#4-3-性别（Sex）" class="headerlink" title="4.3 性别（Sex）"></a>4.3 性别（Sex）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 统计性别和获救的数量</span><br><br><span class="hljs-built_in">print</span>(train_df.Sex.value_counts())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-------------------------------&#x27;</span>)<br><span class="hljs-built_in">print</span>(train_df.groupby(<span class="hljs-string">&#x27;Sex&#x27;</span>)[<span class="hljs-string">&#x27;Survived&#x27;</span>].mean())<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">male      577
female    314
Name: Sex, dtype: int64
-------------------------------
Sex
female    0.742038
male      0.188908
Name: Survived, dtype: float64
</code></pre>
<p>我们注意到，男性的数量偏多，同时数据展现出来的女性的存活率（0.742038）远远高于男性（0.188908）<br>这符合我们在年龄（Name）中的有关猜想。我们在后续的特征处理中应该注意这一特点。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># violinplot(小提琴图)可视化展示</span><br><br>ax = plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>)).add_subplot(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)<br>sns.violinplot(x=<span class="hljs-string">&#x27;Sex&#x27;</span>, y=<span class="hljs-string">&#x27;Age&#x27;</span>, hue=<span class="hljs-string">&#x27;Survived&#x27;</span>, palette=<span class="hljs-string">&quot;Set2&quot;</span>, data=train_df.dropna(), split=<span class="hljs-literal">True</span>)<br>ax.set_xlabel(<span class="hljs-string">&#x27;Sex&#x27;</span>, size=<span class="hljs-number">13</span>)<br>ax.set_xticklabels([<span class="hljs-string">&#x27;Female&#x27;</span>, <span class="hljs-string">&#x27;male&#x27;</span>], size=<span class="hljs-number">12</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;Age&#x27;</span>, size=<span class="hljs-number">13</span>)<br>ax.legend(fontsize=<span class="hljs-number">12</span>,loc=<span class="hljs-string">&#x27;best&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">&lt;matplotlib.legend.Legend at 0x24b9e256f40&gt;
</code></pre>
<p><img src="/img/output_22_1.png" srcset="/img/loading.gif" lazyload></p>
<p>图例中0表示’Survived’=0，即未获救；图表具有多个维度，可以反映不同性别以及是否获救的乘客的大致分布情况。<br>分析结果显示，无论男女中青年容易获救；相比于女性，男性老年和小孩的获救比例更大。</p>
<h4 id="4-4-Frae-票价"><a href="#4-4-Frae-票价" class="headerlink" title="4.4 Frae(票价)"></a>4.4 Frae(票价)</h4><p>我们分别绘制票价的总体分布图和dead和alive类型的票价分布对比图</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 票价的总体分布图</span><br>fig = plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">6</span>))<br>ax = plt.subplot2grid((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>), colspan=<span class="hljs-number">2</span>)<br><br>ax.tick_params(labelsize=<span class="hljs-number">10</span>)<br>ax.set_title(<span class="hljs-string">&#x27;Fare dist&#x27;</span>, size=<span class="hljs-number">13</span>)<br>sns.kdeplot(train_df.Fare, ax=ax)<br>sns.distplot(train_df.Fare,label=<span class="hljs-string">&#x27;fare&#x27;</span>, ax=ax)<br>ax.legend(fontsize=<span class="hljs-number">15</span>)<br>pos = <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">201</span>,<span class="hljs-number">25</span>)<br>ax.set_xticks(pos)<br>ax.set_xlim([<span class="hljs-number">0</span>, <span class="hljs-number">200</span>])<br>ax.set_xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>ax.set_ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br><br><span class="hljs-comment"># dead和alive分别统计的票价分布曲线对比图</span><br>ax1 = plt.subplot2grid((<span class="hljs-number">2</span>,<span class="hljs-number">2</span>), (<span class="hljs-number">1</span>,<span class="hljs-number">0</span>), colspan=<span class="hljs-number">2</span>)<br>ax1.tick_params(labelsize=<span class="hljs-number">10</span>)<br>sns.distplot(train_df[train_df.Survived==<span class="hljs-number">0</span>].Fare, ax=ax1,hist=<span class="hljs-literal">False</span>, label=<span class="hljs-string">&#x27;dead&#x27;</span>, color=<span class="hljs-string">&#x27;r&#x27;</span>)<br>sns.distplot(train_df[train_df.Survived==<span class="hljs-number">1</span>].Fare, ax=ax1,hist=<span class="hljs-literal">False</span>, label=<span class="hljs-string">&#x27;alive&#x27;</span>,  color=<span class="hljs-string">&#x27;b&#x27;</span>)<br>ax1.set_xlim([<span class="hljs-number">0</span>,<span class="hljs-number">200</span>])<br>ax1.legend(fontsize=<span class="hljs-number">12</span>)<br><br>ax1.set_xlabel(<span class="hljs-string">&#x27;Fare&#x27;</span>, size=<span class="hljs-number">12</span>)<br>ax1.set_ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0, 0.5, &#39;&#39;)
</code></pre>
<p><img src="/img/output_25_1.png" srcset="/img/loading.gif" lazyload></p>
<p>图中可以看到，低票价（Fare）的乘客中死亡比例极高，而高票价的乘客中获救的人似乎要更多。<br>同时我们注意到，Fare的分布太宽，后续数据处理可以做一下scaling，加速模型收敛。</p>
<h4 id="4-5-表亲和直亲-SibSp和Parch"><a href="#4-5-表亲和直亲-SibSp和Parch" class="headerlink" title="4.5 表亲和直亲(SibSp和Parch)"></a>4.5 表亲和直亲(SibSp和Parch)</h4><p>SibSp描述了泰坦尼克号上与乘客同行的兄弟姐妹（Siblings）和配偶（Spouse）数目；<br>而Parch描述了泰坦尼克号上与乘客同行的家长（Parents）和孩子（Children）数目。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先查看数据分布特征</span><br>fig = plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">5</span>))<br>ax1 = fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>sns.countplot(train_df.SibSp)<br>ax1.set_title(<span class="hljs-string">&#x27;SibSp&#x27;</span>, size=<span class="hljs-number">13</span>)<br>ax1.set_xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>ax1.set_ylabel(<span class="hljs-string">&#x27;Count&#x27;</span>,size=<span class="hljs-number">11</span>)<br><br>ax2 = fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, sharex=ax1)<br>sns.countplot(train_df.Parch)<br>ax2.set_xlabel(<span class="hljs-string">&#x27;Parch&#x27;</span>, size=<span class="hljs-number">13</span>)<br>ax2.set_ylabel(<span class="hljs-string">&#x27;Count&#x27;</span>,size=<span class="hljs-number">11</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0, 0.5, &#39;Count&#39;)
</code></pre>
<p><img src="/img/output_28_1.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 统计对比不同sibsp &amp; parch情况下的获救比例</span><br><br>fig = plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">6</span>))<br>ax1 = fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>train_df.groupby(<span class="hljs-string">&#x27;SibSp&#x27;</span>)[<span class="hljs-string">&#x27;Survived&#x27;</span>].mean().plot(kind=<span class="hljs-string">&#x27;bar&#x27;</span>,ax= ax1,color=<span class="hljs-string">&#x27;lightseagreen&#x27;</span>)<br>ax1.set_title(<span class="hljs-string">&#x27;Sibsp Survived Rate&#x27;</span>, size=<span class="hljs-number">12</span>)<br>ax1.set_xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br><br>ax2 = fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>train_df.groupby(<span class="hljs-string">&#x27;Parch&#x27;</span>)[<span class="hljs-string">&#x27;Survived&#x27;</span>].mean().plot(kind=<span class="hljs-string">&#x27;bar&#x27;</span>,ax= ax2,color=<span class="hljs-string">&#x27;m&#x27;</span>)<br>ax2.set_title(<span class="hljs-string">&#x27;Parch Survived Rate&#x27;</span>, size=<span class="hljs-number">12</span>)<br>ax2.set_xlabel(<span class="hljs-string">&#x27;&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 0, &#39;&#39;)
</code></pre>
<p><img src="/img/output_29_1.png" srcset="/img/loading.gif" lazyload></p>
<p>分组统计不同亲戚类型,即表亲和直亲(SibSp和Parch)和数量的获救率。我们发现，获救率与亲戚的关系可能并不具有简单的线性关系。</p>
<h3 id="五、特征工程"><a href="#五、特征工程" class="headerlink" title="五、特征工程"></a>五、特征工程</h3><h4 id="5-1-Name特征处理"><a href="#5-1-Name特征处理" class="headerlink" title="5.1 Name特征处理"></a>5.1 Name特征处理</h4><p>充分挖掘和提取Titanic数据集的特征可以有效提高模型精度。因此，我们对name字段进行挖掘和特征的提取</p>
<h4 id="5-2-Name-Len特征"><a href="#5-2-Name-Len特征" class="headerlink" title="5.2 Name_Len特征"></a>5.2 Name_Len特征</h4><p>由于西方人的名字长度差别较大，且含义丰富，我们首先探索一下名字长度这个特征：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train_df.groupby(train_df.Name.apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x)))[<span class="hljs-string">&#x27;Survived&#x27;</span>].mean().plot(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">5</span>),linewidth=<span class="hljs-number">2</span>,color=<span class="hljs-string">&#x27;g&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Name_length&#x27;</span>,fontsize=<span class="hljs-number">12</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Survived rate&#x27;</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0, 0.5, &#39;Survived rate&#39;)
</code></pre>
<p><img src="/img/output_33_1.png" srcset="/img/loading.gif" lazyload></p>
<p>可以看到名字的长度和获救率还是有一定的正向关系的，可以考虑加入Name_Len特征：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 加入Name_Len特征</span><br>combine_df[<span class="hljs-string">&#x27;Name_Len&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Name&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x))<br><br><span class="hljs-comment"># Name_Len数据分箱</span><br>combine_df[<span class="hljs-string">&#x27;Name_Len&#x27;</span>] = pd.qcut(combine_df[<span class="hljs-string">&#x27;Name_Len&#x27;</span>],<span class="hljs-number">5</span>)<br></code></pre></td></tr></table></figure>

<h5 id="注："><a href="#注：" class="headerlink" title="注："></a>注：</h5><p>数据分箱（也称为离散分箱或分段）是一种数据预处理技术，用于减少次要观察误差的影响，是一种将多个连续值分组为较少数量的“分箱”的方法。</p>
<h4 id="5-3-Title特征"><a href="#5-3-Title特征" class="headerlink" title="5.3 Title特征"></a>5.3 Title特征</h4><p>西方人名字中含有的称谓信息(数据集中名字中间的单词)也可以在很大程度上反映一个人的身份地位，从数据中提取”Title”（称谓）也可以作为特征，由于有些称谓的人数量过少，我们还需要做一个映射（分组），将一组等效的称谓合并在一起。</p>
<p>几条有关英语称谓的解释：</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Mme：</strong>相当于Mrs</td>
<td><strong>Ms：</strong>Ms.或Mz 美国近来用来称呼婚姻状态不明的妇女</td>
</tr>
<tr>
<td><strong>Jonkheer:</strong> 乡绅</td>
<td><strong>Col：</strong>中校:Lieutenant Colonel(Lt. Col.)上校:Colonel(Col.)</td>
</tr>
<tr>
<td><strong>Lady：</strong>贵族夫人的称呼</td>
<td><strong>Major：</strong>少校</td>
</tr>
<tr>
<td><strong>Don唐：</strong>是西班牙语中贵族和有地位者的尊称</td>
<td><strong>Mlle:</strong> 小姐</td>
</tr>
<tr>
<td><strong>sir：</strong>懂的都懂</td>
<td><strong>Rev：</strong>牧师</td>
</tr>
<tr>
<td><strong>the Countess：</strong>女伯爵</td>
<td><strong>测试集合中的Dona</strong>：女士尊称</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 称谓的提取和合并</span><br>combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Name&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: x.split(<span class="hljs-string">&#x27;, &#x27;</span>)[<span class="hljs-number">1</span>]).apply(<span class="hljs-keyword">lambda</span> x: x.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>])<br>combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>].replace([<span class="hljs-string">&#x27;Don&#x27;</span>,<span class="hljs-string">&#x27;Dona&#x27;</span>, <span class="hljs-string">&#x27;Major&#x27;</span>, <span class="hljs-string">&#x27;Capt&#x27;</span>, <span class="hljs-string">&#x27;Jonkheer&#x27;</span>, <span class="hljs-string">&#x27;Rev&#x27;</span>, <span class="hljs-string">&#x27;Col&#x27;</span>,<span class="hljs-string">&#x27;Sir&#x27;</span>,<span class="hljs-string">&#x27;Dr&#x27;</span>],<span class="hljs-string">&#x27;Mr&#x27;</span>)<br>combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>].replace([<span class="hljs-string">&#x27;Mlle&#x27;</span>,<span class="hljs-string">&#x27;Ms&#x27;</span>], <span class="hljs-string">&#x27;Miss&#x27;</span>)<br>combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>].replace([<span class="hljs-string">&#x27;the Countess&#x27;</span>,<span class="hljs-string">&#x27;Mme&#x27;</span>,<span class="hljs-string">&#x27;Lady&#x27;</span>,<span class="hljs-string">&#x27;Dr&#x27;</span>], <span class="hljs-string">&#x27;Mrs&#x27;</span>)<br><br><span class="hljs-comment"># 分类变量编码，转换为哑变量处理</span><br>df = pd.get_dummies(combine_df[<span class="hljs-string">&#x27;Title&#x27;</span>],prefix=<span class="hljs-string">&#x27;Title&#x27;</span>)<span class="hljs-comment"># prefix：表示列名的前缀</span><br>combine_df = pd.concat([combine_df,df],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<p>在特征探索阶段，我们发现男性和女性的获救率分别为女性的0.742038和男性的0.188908；<br>女性死亡以及男性存活概率明显较低，为了提升模型对于这一类群体的识别能力，我们分析数据并找到了一个重要特征“Family”，同一个family下的生存死亡模式有很大程度上是相关的，例如：有一个family有一个女性死亡，这个family其他的女性的死亡概率也比较高。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#我们标注出这些特殊的family</span><br><br>combine_df[<span class="hljs-string">&#x27;Surname&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Name&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x:x.split(<span class="hljs-string">&#x27;,&#x27;</span>)[<span class="hljs-number">0</span>])<br>dead_female_surname = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(combine_df[(combine_df.Sex==<span class="hljs-string">&#x27;female&#x27;</span>) &amp; (combine_df.Age&gt;=<span class="hljs-number">12</span>)<br>                              &amp; (combine_df.Survived==<span class="hljs-number">0</span>) &amp; ((combine_df.Parch&gt;<span class="hljs-number">0</span>) | (combine_df.SibSp &gt; <span class="hljs-number">0</span>))][<span class="hljs-string">&#x27;Surname&#x27;</span>].values))<br>survive_male_surname = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>(combine_df[(combine_df.Sex==<span class="hljs-string">&#x27;male&#x27;</span>) &amp; (combine_df.Age&gt;=<span class="hljs-number">12</span>)<br>                              &amp; (combine_df.Survived==<span class="hljs-number">1</span>) &amp; ((combine_df.Parch&gt;<span class="hljs-number">0</span>) | (combine_df.SibSp &gt; <span class="hljs-number">0</span>))][<span class="hljs-string">&#x27;Surname&#x27;</span>].values))<br>combine_df[<span class="hljs-string">&#x27;Dead_female_family&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Surname&#x27;</span>].isin(dead_female_surname),<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>combine_df[<span class="hljs-string">&#x27;Survive_male_family&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Surname&#x27;</span>].isin(survive_male_surname),<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>combine_df = combine_df.drop([<span class="hljs-string">&#x27;Name&#x27;</span>,<span class="hljs-string">&#x27;Surname&#x27;</span>],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-4-Age特征"><a href="#5-4-Age特征" class="headerlink" title="5.4  Age特征"></a>5.4  Age特征</h4><p>根据特征探索阶段的分析，小孩的获救率明显较高，可以添加一个小孩标签属性（IsChild）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Age &amp; isChild</span><br>group = combine_df.groupby([<span class="hljs-string">&#x27;Title&#x27;</span>, <span class="hljs-string">&#x27;Pclass&#x27;</span>])[<span class="hljs-string">&#x27;Age&#x27;</span>]<br>combine_df[<span class="hljs-string">&#x27;Age&#x27;</span>] = group.transform(<span class="hljs-keyword">lambda</span> x: x.fillna(x.median()))<br>combine_df = combine_df.drop(<span class="hljs-string">&#x27;Title&#x27;</span>,axis=<span class="hljs-number">1</span>)<br>combine_df[<span class="hljs-string">&#x27;IsChild&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Age&#x27;</span>]&lt;=<span class="hljs-number">12</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>combine_df[<span class="hljs-string">&#x27;Age&#x27;</span>] = pd.cut(combine_df[<span class="hljs-string">&#x27;Age&#x27;</span>],<span class="hljs-number">5</span>)<br>combine_df = combine_df.drop(<span class="hljs-string">&#x27;Age&#x27;</span>,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-5-Familysize"><a href="#5-5-Familysize" class="headerlink" title="5.5  Familysize"></a>5.5  Familysize</h4><p>将上面提取过的Familysize再离散化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分箱，将Familysize=0标注为&#x27;solo&#x27;,Familysize&gt;3为&#x27;big&#x27;，中间为&#x27;normal&#x27;，然后对分类变量编码，转换为哑变量处理</span><br><br>combine_df[<span class="hljs-string">&#x27;FamilySize&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;SibSp&#x27;</span>]+combine_df[<span class="hljs-string">&#x27;Parch&#x27;</span>]==<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Alone&#x27;</span>,<br>                                    np.where(combine_df[<span class="hljs-string">&#x27;SibSp&#x27;</span>]+combine_df[<span class="hljs-string">&#x27;Parch&#x27;</span>]&lt;=<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;Small&#x27;</span>, <span class="hljs-string">&#x27;Big&#x27;</span>))<br>df = pd.get_dummies(combine_df[<span class="hljs-string">&#x27;FamilySize&#x27;</span>],prefix=<span class="hljs-string">&#x27;FamilySize&#x27;</span>)<br>combine_df = pd.concat([combine_df,df],axis=<span class="hljs-number">1</span>).drop([<span class="hljs-string">&#x27;SibSp&#x27;</span>,<span class="hljs-string">&#x27;Parch&#x27;</span>,<span class="hljs-string">&#x27;FamilySize&#x27;</span>],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-6-Ticket特征"><a href="#5-6-Ticket特征" class="headerlink" title="5.6 Ticket特征"></a>5.6 Ticket特征</h4><p>统计发现，【’1’, ‘2’, ‘P’】开头的Ticket获救率更高。可以标注为’High_Survival_Ticket’型票；同理【’A’,’W’,’3’,’7’】为’Low_Survival_Ticket’型票。这样得到High_Survival_Ticket和Low_Survival_Ticket两个新的特征。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">combine_df[<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Ticket&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">str</span>(x)[<span class="hljs-number">0</span>])<br>combine_df[<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>] = combine_df[<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">str</span>(x))<br><br>combine_df[<span class="hljs-string">&#x27;High_Survival_Ticket&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>].isin([<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;P&#x27;</span>]),<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>combine_df[<span class="hljs-string">&#x27;Low_Survival_Ticket&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>].isin([<span class="hljs-string">&#x27;A&#x27;</span>,<span class="hljs-string">&#x27;W&#x27;</span>,<span class="hljs-string">&#x27;3&#x27;</span>,<span class="hljs-string">&#x27;7&#x27;</span>]),<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>combine_df = combine_df.drop([<span class="hljs-string">&#x27;Ticket&#x27;</span>,<span class="hljs-string">&#x27;Ticket_Lett&#x27;</span>],axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-7-Embarked特征"><a href="#5-7-Embarked特征" class="headerlink" title="5.7 Embarked特征"></a>5.7 Embarked特征</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">ax = plt.figure(figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">3</span>)).add_subplot(<span class="hljs-number">111</span>)<br>ax.set_xlim([-<span class="hljs-number">20</span>, <span class="hljs-number">80</span>])<br>sns.kdeplot(train_df[train_df.Embarked==<span class="hljs-string">&#x27;C&#x27;</span>].Age.dropna(), ax=ax, label=<span class="hljs-string">&#x27;C&#x27;</span>)<br>sns.kdeplot(train_df[train_df.Embarked==<span class="hljs-string">&#x27;Q&#x27;</span>].Age.dropna(), ax=ax, label=<span class="hljs-string">&#x27;Q&#x27;</span>)<br>sns.kdeplot(train_df[train_df.Embarked==<span class="hljs-string">&#x27;S&#x27;</span>].Age.dropna(), ax=ax, label=<span class="hljs-string">&#x27;S&#x27;</span>)<br>ax.legend(fontsize=<span class="hljs-number">12</span>)<br>ax.set_title(<span class="hljs-string">&#x27;Embarked Age Dist &#x27;</span>, size=<span class="hljs-number">13</span>)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Text(0.5, 1.0, &#39;Embarked Age Dist &#39;)
</code></pre>
<p><img src="/img/output_49_1.png" srcset="/img/loading.gif" lazyload></p>
<p>Embarked字段只有个别缺失，我们选择数量最多且年龄分布正常的港口进行填充</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 缺失港口信息填充S，并转换为哑变量</span><br><br>combine_df.Embarked = combine_df.Embarked.fillna(<span class="hljs-string">&#x27;S&#x27;</span>)<br>df = pd.get_dummies(combine_df[<span class="hljs-string">&#x27;Embarked&#x27;</span>],prefix=<span class="hljs-string">&#x27;Embarked&#x27;</span>)<br>combine_df = pd.concat([combine_df,df],axis=<span class="hljs-number">1</span>).drop(<span class="hljs-string">&#x27;Embarked&#x27;</span>,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-8-Cabin特征"><a href="#5-8-Cabin特征" class="headerlink" title="5.8 Cabin特征"></a>5.8 Cabin特征</h4><p>Cabin特征大量缺失，我们将其转化为Cabin_isNull特征，取值域为0和1</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">combine_df[<span class="hljs-string">&#x27;Cabin_isNull&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Cabin&#x27;</span>].isnull(),<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>combine_df = combine_df.drop(<span class="hljs-string">&#x27;Cabin&#x27;</span>,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-9-Pclass-amp-Sex特征"><a href="#5-9-Pclass-amp-Sex特征" class="headerlink" title="5.9 Pclass &amp; Sex特征"></a>5.9 Pclass &amp; Sex特征</h4><p>Pclass &amp; Sex特征进行分类数据编码，转化为哑变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Pclass</span><br>df = pd.get_dummies(combine_df[<span class="hljs-string">&#x27;Pclass&#x27;</span>],prefix=<span class="hljs-string">&#x27;Pclass&#x27;</span>)<br>combine_df = pd.concat([combine_df,df],axis=<span class="hljs-number">1</span>).drop(<span class="hljs-string">&#x27;Pclass&#x27;</span>,axis=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Sex</span><br>df = pd.get_dummies(combine_df[<span class="hljs-string">&#x27;Sex&#x27;</span>],prefix=<span class="hljs-string">&#x27;Sex&#x27;</span>)<br>combine_df = pd.concat([combine_df,df],axis=<span class="hljs-number">1</span>).drop(<span class="hljs-string">&#x27;Sex&#x27;</span>,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="5-10-Fare特征"><a href="#5-10-Fare特征" class="headerlink" title="5.10 Fare特征"></a>5.10 Fare特征</h4><p>缺省值用众数填充，之后进行离散化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Fare</span><br>combine_df[<span class="hljs-string">&#x27;Fare&#x27;</span>].fillna(combine_df[<span class="hljs-string">&#x27;Fare&#x27;</span>].dropna().median(),inplace=<span class="hljs-literal">True</span>)<br>combine_df[<span class="hljs-string">&#x27;Low_Fare&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Fare&#x27;</span>]&lt;=<span class="hljs-number">8.662</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>combine_df[<span class="hljs-string">&#x27;High_Fare&#x27;</span>] = np.where(combine_df[<span class="hljs-string">&#x27;Fare&#x27;</span>]&gt;=<span class="hljs-number">26</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)<br>combine_df = combine_df.drop(<span class="hljs-string">&#x27;Fare&#x27;</span>,axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h3 id="六、-模型训练-测试"><a href="#六、-模型训练-测试" class="headerlink" title="六、 模型训练/测试"></a>六、 模型训练/测试</h3><p>查看我们现在有哪些特征：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">combine_df.columns<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">Index([&#39;PassengerId&#39;, &#39;Survived&#39;, &#39;Name_Len&#39;, &#39;Title_Master&#39;, &#39;Title_Miss&#39;,
       &#39;Title_Mr&#39;, &#39;Title_Mrs&#39;, &#39;Dead_female_family&#39;, &#39;Survive_male_family&#39;,
       &#39;IsChild&#39;, &#39;FamilySize_Alone&#39;, &#39;FamilySize_Big&#39;, &#39;FamilySize_Small&#39;,
       &#39;High_Survival_Ticket&#39;, &#39;Low_Survival_Ticket&#39;, &#39;Embarked_C&#39;,
       &#39;Embarked_Q&#39;, &#39;Embarked_S&#39;, &#39;Cabin_isNull&#39;, &#39;Pclass_1&#39;, &#39;Pclass_2&#39;,
       &#39;Pclass_3&#39;, &#39;Sex_female&#39;, &#39;Sex_male&#39;, &#39;Low_Fare&#39;, &#39;High_Fare&#39;],
      dtype=&#39;object&#39;)
</code></pre>
<p>所有特征转化成数值型编码：</p>
<p>LabelEncoder是用来对分类型特征值进行编码，即对不连续的数值或文本进行编码。其中包含以下常用方法：</p>
<ol>
<li>fit(y) ：fit可看做一本空字典，y可看作要塞到字典中的词。</li>
<li>fit_transform(y)：相当于先进行fit再进行transform，即把y塞到字典中去以后再进行transform得到索引值。</li>
<li>inverse_transform(y)：根据索引值y获得原始数据。</li>
<li>transform(y) ：将y转变成索引值。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python">features = combine_df.drop([<span class="hljs-string">&quot;PassengerId&quot;</span>,<span class="hljs-string">&quot;Survived&quot;</span>], axis=<span class="hljs-number">1</span>).columns<br>le = LabelEncoder()<br><span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features:<br>    combine_df[feature]=le.fit_transform(combine_df[feature])<br>    <span class="hljs-comment"># 和以下两行等价</span><br>    <span class="hljs-comment"># le = le.fit(combine_df[feature])# fit(),将所有特征转化成数值型编码</span><br>    <span class="hljs-comment"># combine_df[feature] = le.transform(combine_df[feature])</span><br>combine_df<br></code></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }


<pre><code class="hljs">.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Name_Len</th>
      <th>Title_Master</th>
      <th>Title_Miss</th>
      <th>Title_Mr</th>
      <th>Title_Mrs</th>
      <th>Dead_female_family</th>
      <th>Survive_male_family</th>
      <th>IsChild</th>
      <th>...</th>
      <th>Embarked_Q</th>
      <th>Embarked_S</th>
      <th>Cabin_isNull</th>
      <th>Pclass_1</th>
      <th>Pclass_2</th>
      <th>Pclass_3</th>
      <th>Sex_female</th>
      <th>Sex_male</th>
      <th>Low_Fare</th>
      <th>High_Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1.0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1.0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1.0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0.0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>413</th>
      <td>1305</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>414</th>
      <td>1306</td>
      <td>NaN</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>415</th>
      <td>1307</td>
      <td>NaN</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>416</th>
      <td>1308</td>
      <td>NaN</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>417</th>
      <td>1309</td>
      <td>NaN</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>1309 rows × 26 columns</p>

</div>



<h4 id="6-1-模型搭建"><a href="#6-1-模型搭建" class="headerlink" title="6.1 模型搭建"></a>6.1 模型搭建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">X_all = combine_df.iloc[:<span class="hljs-number">891</span>,:].drop([<span class="hljs-string">&quot;PassengerId&quot;</span>,<span class="hljs-string">&quot;Survived&quot;</span>], axis=<span class="hljs-number">1</span>)<br>Y_all = combine_df.iloc[:<span class="hljs-number">891</span>,:][<span class="hljs-string">&quot;Survived&quot;</span>]<br>X_test = combine_df.iloc[<span class="hljs-number">891</span>:,:].drop([<span class="hljs-string">&quot;PassengerId&quot;</span>,<span class="hljs-string">&quot;Survived&quot;</span>], axis=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h4 id="6-2-模型与参数初始化"><a href="#6-2-模型与参数初始化" class="headerlink" title="6.2 模型与参数初始化"></a>6.2 模型与参数初始化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 考察逻辑回归、支持向量机、最近邻、决策树、随机森林、gbdt、xgbGBDT几类算法的性能</span><br>logreg = LogisticRegression()<br>svc = SVC()<br>knn = KNeighborsClassifier(n_neighbors = <span class="hljs-number">5</span>)<br>decision_tree = DecisionTreeClassifier()<br>random_forest = RandomForestClassifier(n_estimators=<span class="hljs-number">300</span>,min_samples_leaf=<span class="hljs-number">4</span>,class_weight=&#123;<span class="hljs-number">0</span>:<span class="hljs-number">0.745</span>,<span class="hljs-number">1</span>:<span class="hljs-number">0.255</span>&#125;)<br>gbdt = GradientBoostingClassifier(n_estimators=<span class="hljs-number">300</span>,learning_rate=<span class="hljs-number">0.05</span>,max_depth=<span class="hljs-number">3</span>)<br>xgb = XGBClassifier(max_depth=<span class="hljs-number">6</span>, n_estimators=<span class="hljs-number">400</span>, learning_rate=<span class="hljs-number">0.02</span>)<br>lgb = LGBMClassifier(max_depth=<span class="hljs-number">6</span>, n_estimators=<span class="hljs-number">300</span>, learning_rate=<span class="hljs-number">0.02</span>)<br>clfs = [logreg, svc, knn, decision_tree, random_forest, gbdt, xgb, lgb]<br><br></code></pre></td></tr></table></figure>

<h4 id="6-3-网格参数搜索"><a href="#6-3-网格参数搜索" class="headerlink" title="6.3 网格参数搜索"></a>6.3 网格参数搜索</h4><p>sklearn.model_selection库中有GridSearchCV方法，作用是搜索模型的最优参数。<br>我们使用GridSearchCV初步选择参数，后续再不断返回调参。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># clfs = [logreg, svc, knn, decision_tree, random_forest, gbdt, xgb, lgb]</span><br><br><span class="hljs-comment">#XGboost 参数搜索</span><br>gsCv = GridSearchCV(xgb,<br>                   &#123;<span class="hljs-string">&#x27;max_depth&#x27;</span>: [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>],<br>                    <span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">300</span>,<span class="hljs-number">400</span>,<span class="hljs-number">500</span>],<br>                   <span class="hljs-string">&#x27;learning_rate&#x27;</span>:[<span class="hljs-number">0.01</span>,<span class="hljs-number">0.02</span>,<span class="hljs-number">0.03</span>,<span class="hljs-number">0.04</span>]<br>                   &#125;)<br>gsCv.fit(X_all,Y_all)<br><br><span class="hljs-built_in">print</span>(gsCv.best_score_)<br><span class="hljs-built_in">print</span>(gsCv.best_params_)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">0.8911116690728769
&#123;&#39;learning_rate&#39;: 0.02, &#39;max_depth&#39;: 6, &#39;n_estimators&#39;: 400&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#lightgbm 参数搜索</span><br>gsCv = GridSearchCV(lgb,<br>                   &#123;<span class="hljs-string">&#x27;max_depth&#x27;</span>: [<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>],<br>                    <span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">200</span>,<span class="hljs-number">300</span>,<span class="hljs-number">400</span>,<span class="hljs-number">500</span>],<br>                   <span class="hljs-string">&#x27;learning_rate&#x27;</span>:[<span class="hljs-number">0.01</span>,<span class="hljs-number">0.02</span>,<span class="hljs-number">0.03</span>,<span class="hljs-number">0.04</span>]<br>                   &#125;)<br>gsCv.fit(X_all,Y_all)<br><br><span class="hljs-built_in">print</span>(gsCv.best_score_)<br><span class="hljs-built_in">print</span>(gsCv.best_params_)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">0.8866172870504048
&#123;&#39;learning_rate&#39;: 0.02, &#39;max_depth&#39;: 6, &#39;n_estimators&#39;: 300&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#GBDT 参数搜索</span><br>gsCv = GridSearchCV(gbdt,<br>                   &#123;<span class="hljs-string">&#x27;max_depth&#x27;</span>: [<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],<br>                    <span class="hljs-string">&#x27;n_estimators&#x27;</span>: [<span class="hljs-number">200</span>,<span class="hljs-number">300</span>,<span class="hljs-number">400</span>,<span class="hljs-number">500</span>],<br>                   <span class="hljs-string">&#x27;learning_rate&#x27;</span>:[<span class="hljs-number">0.04</span>,<span class="hljs-number">0.05</span>,<span class="hljs-number">0.06</span>]<br>                   &#125;)<br>gsCv.fit(X_all,Y_all)<br><br><span class="hljs-built_in">print</span>(gsCv.best_score_)<br><span class="hljs-built_in">print</span>(gsCv.best_params_)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">0.8899943506371226
&#123;&#39;learning_rate&#39;: 0.05, &#39;max_depth&#39;: 3, &#39;n_estimators&#39;: 300&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#KNN 参数搜索</span><br>gsCv = GridSearchCV(knn,<br>                   &#123;<span class="hljs-string">&#x27;n_neighbors&#x27;</span>:[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]&#125;)<br>gsCv.fit(X_all,Y_all)<br><br><span class="hljs-built_in">print</span>(gsCv.best_score_)<br><span class="hljs-built_in">print</span>(gsCv.best_params_)<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">0.8529659155106396
&#123;&#39;n_neighbors&#39;: 5&#125;
</code></pre>
<h4 id="6-4-K折交叉验证"><a href="#6-4-K折交叉验证" class="headerlink" title="6.4 K折交叉验证"></a>6.4 K折交叉验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># K折交叉验证</span><br><br>kfold = <span class="hljs-number">10</span><br>cv_results = []<br><span class="hljs-keyword">for</span> classifier <span class="hljs-keyword">in</span> clfs :<br>    cv_results.append(cross_val_score(classifier, X_all.values, y = Y_all.values, scoring = <span class="hljs-string">&quot;accuracy&quot;</span>, cv = kfold, n_jobs=<span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># cv_results 为8*10的结果矩阵</span><br>cv_means = []<br>cv_std = []<br><span class="hljs-keyword">for</span> cv_result <span class="hljs-keyword">in</span> cv_results:<br>    cv_means.append(cv_result.mean())<br>    cv_std.append(cv_result.std())<br><br>ag = [<span class="hljs-string">&quot;logreg&quot;</span>,<span class="hljs-string">&quot;SVC&quot;</span>,<span class="hljs-string">&#x27;KNN&#x27;</span>,<span class="hljs-string">&#x27;decision_tree&#x27;</span>,<span class="hljs-string">&quot;random_forest&quot;</span>,<span class="hljs-string">&quot;GBDT&quot;</span>,<span class="hljs-string">&quot;xgbGBDT&quot;</span>, <span class="hljs-string">&quot;LGB&quot;</span>]<br>cv_res = pd.DataFrame(&#123;<span class="hljs-string">&quot;CrossValMeans&quot;</span>:cv_means,<span class="hljs-string">&quot;CrossValerrors&quot;</span>: cv_std,<br>                       <span class="hljs-string">&quot;Algorithm&quot;</span>:ag&#125;)<br><br>g = sns.barplot(<span class="hljs-string">&quot;CrossValMeans&quot;</span>,<span class="hljs-string">&quot;Algorithm&quot;</span>,data = cv_res, palette=<span class="hljs-string">&quot;Blues&quot;</span>)<br>g.set_xlabel(<span class="hljs-string">&quot;CrossValMeans&quot;</span>,fontsize=<span class="hljs-number">10</span>)<br>g.set_ylabel(<span class="hljs-string">&#x27;&#x27;</span>)<br>plt.xticks(rotation=<span class="hljs-number">30</span>)<br>g = g.set_title(<span class="hljs-string">&quot;10-fold Cross validation scores&quot;</span>,fontsize=<span class="hljs-number">12</span>)<br></code></pre></td></tr></table></figure>


<p><img src="/img/output_17_1.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 展示10-fold Cross validation的均值得分结果</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125; : &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(ag[i],cv_means[i]))<br></code></pre></td></tr></table></figure>

<pre><code class="hljs">logreg : 0.8731585518102373
SVC : 0.8776404494382023
KNN : 0.8540823970037452
decision_tree : 0.8652559300873908
random_forest : 0.8563920099875156
GBDT : 0.8832459425717852
xgbGBDT : 0.8843820224719101
LGB : 0.8799001248439451
</code></pre>
<h4 id="6-5-训练-验证过程可视化"><a href="#6-5-训练-验证过程可视化" class="headerlink" title="6.5 训练/验证过程可视化"></a>6.5 训练/验证过程可视化</h4><p>将模型训练过程的学习曲线打印出来，看下是否存在过拟合/欠拟合情况</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用sklearn的learning_curve得到training_score和cv_score，使用matplotlib画出learning curve</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_learning_curve</span>(<span class="hljs-params">clf, title, X, y, ylim=<span class="hljs-literal">None</span>, cv=<span class="hljs-literal">None</span>, n_jobs=<span class="hljs-number">3</span>, train_sizes=np.linspace(<span class="hljs-params"><span class="hljs-number">.05</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">5</span></span>)</span>):</span><br>    train_sizes, train_scores, test_scores = learning_curve(<br>        clf, X, y, train_sizes=train_sizes)<br>    train_scores_mean = np.mean(train_scores, axis=<span class="hljs-number">1</span>)<br>    train_scores_std = np.std(train_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_mean = np.mean(test_scores, axis=<span class="hljs-number">1</span>)<br>    test_scores_std = np.std(test_scores, axis=<span class="hljs-number">1</span>)<br>    <br>    ax = plt.figure().add_subplot(<span class="hljs-number">111</span>)<br>    ax.set_title(title)<br>    <span class="hljs-keyword">if</span> ylim <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        ax.ylim(*ylim)<br>    ax.set_xlabel(<span class="hljs-string">u&quot;train_num_of_samples&quot;</span>)<br>    ax.set_ylabel(<span class="hljs-string">u&quot;score&quot;</span>)<br><br>    ax.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, <br>                     alpha=<span class="hljs-number">0.1</span>, color=<span class="hljs-string">&quot;b&quot;</span>)<br>    ax.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, <br>                     alpha=<span class="hljs-number">0.1</span>, color=<span class="hljs-string">&quot;r&quot;</span>)<br>    ax.plot(train_sizes, train_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;b&quot;</span>, label=<span class="hljs-string">u&quot;train score&quot;</span>)<br>    ax.plot(train_sizes, test_scores_mean, <span class="hljs-string">&#x27;o-&#x27;</span>, color=<span class="hljs-string">&quot;r&quot;</span>, label=<span class="hljs-string">u&quot;testCV score&quot;</span>)<br><br>    ax.legend(loc=<span class="hljs-string">&quot;best&quot;</span>)<br><br>    midpoint = ((train_scores_mean[-<span class="hljs-number">1</span>] + train_scores_std[-<span class="hljs-number">1</span>]) + (test_scores_mean[-<span class="hljs-number">1</span>] - test_scores_std[-<span class="hljs-number">1</span>])) / <span class="hljs-number">2</span><br>    diff = (train_scores_mean[-<span class="hljs-number">1</span>] + train_scores_std[-<span class="hljs-number">1</span>]) - (test_scores_mean[-<span class="hljs-number">1</span>] - test_scores_std[-<span class="hljs-number">1</span>])<br>    <span class="hljs-keyword">return</span> midpoint, diff<br><br>alg_list=[<span class="hljs-string">&#x27;logreg&#x27;</span>, <span class="hljs-string">&#x27;svc&#x27;</span>, <span class="hljs-string">&#x27;knn&#x27;</span>, <span class="hljs-string">&#x27;decision_tree&#x27;</span>, <span class="hljs-string">&#x27;random_forest&#x27;</span>, <span class="hljs-string">&#x27;gbdt&#x27;</span>, <span class="hljs-string">&#x27;xgb&#x27;</span>, <span class="hljs-string">&#x27;lgb&#x27;</span>]<br><br>plot_learning_curve(clfs[<span class="hljs-number">0</span>], alg_list[<span class="hljs-number">0</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">1</span>], alg_list[<span class="hljs-number">1</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">2</span>], alg_list[<span class="hljs-number">2</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">3</span>], alg_list[<span class="hljs-number">3</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">4</span>], alg_list[<span class="hljs-number">4</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">5</span>], alg_list[<span class="hljs-number">5</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">6</span>], alg_list[<span class="hljs-number">6</span>], X_all, Y_all)<br>plot_learning_curve(clfs[<span class="hljs-number">7</span>], alg_list[<span class="hljs-number">7</span>], X_all, Y_all)<br></code></pre></td></tr></table></figure>




<pre><code class="hljs">(0.8944812361959231, 0.04456088047192275)
</code></pre>
<p><img src="/img/output_74_1.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_2.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_3.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_4.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_5.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_6.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_7.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/img/output_74_8.png" srcset="/img/loading.gif" lazyload></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score<br><br><span class="hljs-comment"># 定义集成框架</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Bagging</span>(<span class="hljs-params"><span class="hljs-built_in">object</span></span>):</span><br>    <span class="hljs-comment"># sklearn机器学习算法的实现都属于estimators的子类：</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self,estimators</span>):</span><br>        self.estimator_names = []<br>        self.estimators = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> estimators:<br>            self.estimator_names.append(i[<span class="hljs-number">0</span>])<br>            self.estimators.append(i[<span class="hljs-number">1</span>])<br>        self.clf = LogisticRegression()<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span>(<span class="hljs-params">self, train_x, train_y</span>):</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> self.estimators:<br>            i.fit(train_x,train_y)<br>        x = np.array([i.predict(train_x) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> self.estimators]).T<br>        y = train_y<br>        self.clf.fit(x, y)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span>(<span class="hljs-params">self,x</span>):</span><br>        x = np.array([i.predict(x) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> self.estimators]).T<br>        <span class="hljs-comment">#print(x)</span><br>        <span class="hljs-keyword">return</span> self.clf.predict(x)<br>        <br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">score</span>(<span class="hljs-params">self,x,y</span>):</span><br>        s = precision_score(y,self.predict(x))<br>        <span class="hljs-comment">#print(s)</span><br>        <span class="hljs-keyword">return</span> s<br></code></pre></td></tr></table></figure>

<h4 id="6-6-模型集成与验证（Bagging）"><a href="#6-6-模型集成与验证（Bagging）" class="headerlink" title="6.6 模型集成与验证（Bagging）"></a>6.6 模型集成与验证（Bagging）</h4><p>选择训练结果最好的四个基学习器进行集成（Bagging）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># logreg = LogisticRegression()</span><br><span class="hljs-comment"># random_forest = RandomForestClassifier(n_estimators=300,min_samples_leaf=4,class_weight=&#123;0:0.745,1:0.255&#125;)</span><br><span class="hljs-comment"># gbdt = GradientBoostingClassifier(n_estimators=500,learning_rate=0.03,max_depth=3)</span><br><span class="hljs-comment">#xgb = XGBClassifier(max_depth=3, n_estimators=500, learning_rate=0.03)</span><br><span class="hljs-comment">#clfs = [logreg, svc, knn, decision_tree, random_forest, gbdt, xgb]</span><br><br><span class="hljs-comment"># 选择训练结果最好的四个基学习器集成（Bagging）</span><br><br>bag = Bagging([(<span class="hljs-string">&#x27;xgb&#x27;</span>,xgb),(<span class="hljs-string">&#x27;logreg&#x27;</span>,logreg),(<span class="hljs-string">&#x27;gbdt&#x27;</span>,gbdt), (<span class="hljs-string">&quot;lgb&quot;</span>, lgb)])<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score<br></code></pre></td></tr></table></figure>

<p>X_all，Y_all中按照4：1的比例划分训练数据和测试数据，简化起见没有划分验证集（validation data）用于参数调优，使用训练数据训练我们的集成模型。在划分的测试集上进行预测，并计算模型准确率（Accuracy）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python">score = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">20</span>):<br>    num_test = <span class="hljs-number">0.20</span><br>    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all.values, Y_all.values, test_size=num_test)<br>    bag.fit(X_train, Y_train)<br>    <span class="hljs-comment">#Y_test = bag.predict(X_test)</span><br>    acc_ = <span class="hljs-built_in">round</span>(bag.score(X_cv, Y_cv) * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)<br>    score+=acc_<br>score/<span class="hljs-number">20</span><br></code></pre></td></tr></table></figure>




<pre><code class="hljs">88.43750000000001
</code></pre>
<h3 id="七、进行预测"><a href="#七、进行预测" class="headerlink" title="七、进行预测"></a>七、进行预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># submission存储了预测结果</span><br>bag.fit(X_all.values, Y_all.values)<br>Y_test = bag.predict(X_test.values).astype(<span class="hljs-built_in">int</span>)<br>submission = pd.DataFrame(&#123;<br>        <span class="hljs-string">&quot;PassengerId&quot;</span>: test_df[<span class="hljs-string">&quot;PassengerId&quot;</span>],<br>        <span class="hljs-string">&quot;Survived&quot;</span>: Y_test<br>    &#125;)<br>submission.to_csv(<span class="hljs-string">r&#x27;predictedData.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>

<h3 id="八、评价与总结"><a href="#八、评价与总结" class="headerlink" title="八、评价与总结"></a>八、评价与总结</h3><ul>
<li>数据集选择了经典的kaggle数据竞赛中的Titanic数据集。对于我这样的数据科学、机器学习初学者来说，在该数据集基础上可以找到大量来自大神的实现参考，利于快速上手入门；</li>
<li>没有花时间在’’炼丹’’上，只是使用sklearn.model_selection模块中的网格参数搜索函数GridSearchCV进行了较为简单的参数选择。不过我们还是在训练集和测试集都表现出了较高的精度 ，同时没有明显的过拟合或者欠拟合现象。</li>
<li>起初只是想学习并做一个使用GBDT算法的小项目（基于XGboost），但是发现了大神使用集成的方法进行过相关的实现，所以虚心进行了学习 (•ิ_•ิ)</li>
<li>本人知识，经验十分有限，如果有处理不当或者错误的地方还请谅解。</li>
</ul>
<h3 id="完结撒花"><a href="#完结撒花" class="headerlink" title="完结撒花"></a>完结撒花</h3><p>｡:.ﾟヽ(｡◕‿◕｡)ﾉﾟ.:｡+ﾟ</p>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Machine-Learning/" class="category-chain-item">Machine Learning</a>
  
  
    <span>></span>
    
  <a href="/categories/Machine-Learning/Kaggle/" class="category-chain-item">Kaggle</a>
  
  
    <span>></span>
    
  <a href="/categories/Machine-Learning/Kaggle/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/" class="category-chain-item">集成学习</a>
  
  

  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/">#集成学习</a>
      
        <a href="/tags/Titanic/">#Titanic</a>
      
        <a href="/tags/Kaggle/">#Kaggle</a>
      
        <a href="/tags/ML/">#ML</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>kaggle Titanic问题(集成学习)</div>
      <div>https://e-alan.github.io/2022/11/03/kaggle%20Titanic%E9%97%AE%E9%A2%98(%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0)/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Yubiao Wang</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2022年11月3日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/10/18/Python%E8%AE%A1%E7%AE%97%E5%9C%86%E5%91%A8%E7%8E%87/" title="Python计算圆周率">
                        <span class="hidden-mobile">Python计算圆周率</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'E-Alan/blog-s-comments');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  






    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?66fe493fc83f85768cab806da37aa086";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  

  
    
  




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>

  <script defer src="/js/leancloud.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
